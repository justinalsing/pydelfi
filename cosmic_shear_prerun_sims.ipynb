{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import distributions.priors as priors\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and load in data and simulations...\n",
    "\n",
    "# Fiducial parameters about which data compression was performed\n",
    "theta_fiducial = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "\n",
    "# Set up the truncated Gaussian prior...\n",
    "\n",
    "# Prior parameter boundaries\n",
    "lower = np.array([0, 0.4, 0, 0.4, 0.7])\n",
    "upper = np.array([1, 1.2, 0.1, 1.0, 1.3])\n",
    "\n",
    "# Prior mean and covariance\n",
    "prior_mean = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "Q = np.eye(5)*np.array([0.1, 0.1, 0.05, 0.3, 0.3])**2\n",
    "\n",
    "# Create prior over parameters\n",
    "prior = priors.TruncatedGaussian(prior_mean, Q, lower, upper)\n",
    "\n",
    "# Import data summaries, simulated data summaries and corresponding parameters, and inverse Fisher matrix...\n",
    "\n",
    "# NOTE: The compressed summaries should be in the form of pseudo maximum-likelihood parameter estimators\n",
    "# ie, if you are using the score of an approximate log-likelihood L, you should use compressed summaries\n",
    "# t = \\theta_\\mathrm{fiducial} + F^{-1}\\nabla L where F is the approximate Fisher matrix\n",
    "\n",
    "# Compressed data vector\n",
    "data = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/compressed_data.dat')\n",
    "\n",
    "# Parameters at which sims were run\n",
    "sim_params = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/simulations_parameters.dat')\n",
    "\n",
    "# Compressed data for each simulation (corresponding to parameters above)\n",
    "sim_data = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/simulations_compressed_data.dat')\n",
    "\n",
    "# Inverse Fisher matrix: this can be a bit rough, no biggie\n",
    "Finv = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/Finv.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Delfi object...\n",
    "\n",
    "# Create ensemble of NDEs\n",
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=5, n_data=5, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=0),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=5, n_data=5, n_components=1, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=1),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=5, n_data=5, n_components=2, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=2),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=5, n_data=5, n_components=3, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=3),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=5, n_data=5, n_components=4, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=4),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=5, n_data=5, n_components=5, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=5)]\n",
    "\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiEnsemble = delfi.Delfi(data, prior, NDEs, Finv=Finv, theta_fiducial=theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results_prerun/\",\n",
    "                       input_normalization=\"fisher\")\n",
    "\n",
    "# Load in the simulations\n",
    "DelfiEnsemble.load_simulations(sim_data, sim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training step to inirialize the network\n",
    "DelfiEnsemble.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "DelfiEnsemble.train_ndes(training_data=[DelfiEnsemble.x_train, DelfiEnsemble.y_train], epochs=500, patience=20, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC sample the learned posterior (using the sampler EMCEE)\n",
    "posterior_samples = DelfiEnsemble.emcee_sample(DelfiEnsemble.log_posterior_stacked, [DelfiEnsemble.posterior_samples[-i,:] for i in range(DelfiEnsemble.nwalkers)], burn_in_chain=100, main_chain=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the recovered posterior\n",
    "\n",
    "plt.close()\n",
    "columnwidth = 40 # cm\n",
    "aspect = 1.67*2\n",
    "pts_per_inch = 72.27\n",
    "inch_per_cm = 2.54\n",
    "width = columnwidth/inch_per_cm\n",
    "plt.rcParams.update({'figure.figsize': [width, width / aspect],\n",
    "                 'backend': 'pdf',\n",
    "                 'font.size': 14,\n",
    "                 'legend.fontsize': 'small',\n",
    "                 'legend.frameon': False,\n",
    "                 'legend.loc': 'best',\n",
    "                 'lines.markersize': 3,\n",
    "                 'lines.linewidth': .5,\n",
    "                 'axes.linewidth': .5,\n",
    "                 'axes.edgecolor': 'black'})\n",
    "\n",
    "\n",
    "g = plots.getSubplotPlotter(width_inch = 12)\n",
    "g.settings.figure_legend_frame = False\n",
    "g.settings.alpha_filled_add=0.6\n",
    "g.settings.axes_fontsize=14\n",
    "g.settings.legend_fontsize=16\n",
    "g.settings.lab_fontsize=20\n",
    "\n",
    "names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s']\n",
    "labels = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s']\n",
    "ranges = dict(zip(names, [ [lower[i], upper[i]] for i in range(len(names)) ]))\n",
    "\n",
    "samples = [posterior_samples]\n",
    "mc_samples = [MCSamples(samples=s, names = names, labels = labels, ranges = ranges) for s in samples]\n",
    "\n",
    "g.triangle_plot(mc_samples, normalized=True)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    for j in range(0, i+1):\n",
    "        ax = g.subplots[i,j]\n",
    "        xtl = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(xtl, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
